# [ACE-Step](https://github.com/ace-step/ACE-Step) fork

## Progress

* Separate data preprocessing (music and text encoding) and training
* Enable gradient checkpointing
* Cast everything to bf16

Now I can run the training on a single RTX 3080 with < 10 GB VRAM and 0.3 it/s speed, using music duration < 360 seconds and LoRA rank = 64.

## Usage

For example, I want to train a LoRA for Sawano Hiroyuki (澤野 弘之)'s style.

1. Create a dataset that only contains the filenames, not the audio data:
    ```pwsh
    python convert2hf_dataset_new.py --data_dir C:\data\sawano --output_name C:\data\sawano_filenames"
    ```
    where `--data_dir` is a directory containing audio files.

2. Load the audios, do the preprocessing, save to a new dataset:
    ```pwsh
    python preprocess_dataset_new.py --input_name C:\data\sawano_filenames --output_name C:\data\sawano_prep
    ```
    Currently this will take a lot of disk space. 100 songs of < 360 seconds take ~8 GB. This can be optimized.

    If you modify the data files or the code and re-generate the dataset, you may need to clear the cache like `~/.cache/huggingface/datasets/generator`.

3. Do the training:
    ```pwsh
    python trainer_new.py --dataset_path C:\data\sawano_prep --exp_name sawano
    ```
    The LoRA will be saved to the directory `./checkpoints`. I recommend to clear this directory before training, otherwise the LoRA may not be correctly saved.

    Note that my script uses Wandb rather than TensorBoard. If you don't need it, you can remove the `WandbLogger`.

## Tips

* If you don't have experience, you can first try to train with a single audio and make sure that it can be overfitted. This is a sanity check of the training pipeline
* We can freeze the lyrics decoder and only train the transformer using `config/lora_config_transformer_only.json`. I think training the lyrics decoder is needed only when adding a new language
* After training, when loading the LoRA in ComfyUI, we need to set the lora weight to `alpha / sqrt(rank)` (for rslora) or `alpha / rank` (for non-rslora). For example, if rank = 64, alpha = 1, rslora is enabled, then the lora weight should be `1 / sqrt(64) = 0.125`

## TODO

* How to normalize the audio loudness before preprocessing? It seems the audios generated by ACE-Step usually have loudness in -16 .. -12 LUFS, and they don't follow prompts like 'loud' and 'quiet'
* Use regularization audios, like regularization images for image LoRA training
